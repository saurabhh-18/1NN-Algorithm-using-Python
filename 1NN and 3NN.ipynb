{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Dataset Iris\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris['data'],iris['target'], random_state=186)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imported IRIS dataset here and splitted it using the train_test_split function and selected the random state as my birthdate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 4) (38, 4) (112,) (38,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Euclidean Distance\n",
    "\n",
    "def euc_distance(x,y) :\n",
    "    euc_calc = np.empty(len(x))\n",
    "    for i in range(len(x)) :\n",
    "        euc_calc[i] =(x[i] - y[i]) ** 2\n",
    "    answer = np.sum(euc_calc) ** 0.5\n",
    "    return(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now i am using function min_finder that will give us the minimum value from array/list\n",
    "\n",
    "import math\n",
    "def min_finder(x):\n",
    "    \n",
    "    min = math.inf\n",
    "    for i in range (len(X)):\n",
    "        if X[i] < min:\n",
    "            min = X[i]\n",
    "    return min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now using function argmin_finder to get the index value of the minimum value which we got previously\n",
    "\n",
    "def argmin_finder(X):\n",
    "    min = math.inf\n",
    "    argmin = 0\n",
    "    for i in range (len(X)):\n",
    "        if X[i] < min:\n",
    "            min = X[i]\n",
    "            argmin = i\n",
    "    return argmin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the nearest distance by creating \n",
    "\n",
    "distance = np.empty(len(X_test)*len(X_train)).reshape(len(X_test),len(X_train))\n",
    "for i in range(len(X_test)):\n",
    "    for j in range(len(X_train)):\n",
    "        distance[i,j] = euc_distance(X_test[i],X_train[j])\n",
    "        \n",
    "        \n",
    "\n",
    "y_pred = np.empty(len(X_test))\n",
    "for i in range(len(X_test)):\n",
    "    y_pred[i] = y_train[argmin_finder(distance[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02631578947368421"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_count = sum(y_pred!=y_test)\n",
    "error_rate = (error_count/len(X_test))\n",
    "error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading and splitting the dataset successfully first calcluated the euclidean distance after that using the min_finder function calculated the minimum value from the whole array.\n",
    "\n",
    "After using the min_finder function, used the argmin_finder for getting the index value of that particular minimum value. lastly created the one empty set to get the distance between test and train sample and stored that into the y_pred to get the final error rate for the 1 nearest neighbour.\n",
    "\n",
    "I have got the error rate as 0.0263 and accuracy as 0.973 that is 97%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3NN algorithm for the dataset IRIS\n",
    "\n",
    "def argmin_finder_3(x):\n",
    "    \n",
    "    min = math.inf\n",
    "    x_c=[i for i in x]\n",
    "    argmin = [0,1,2]\n",
    "    for i in range(len(x_c)):\n",
    "        if x_c[i] < min:\n",
    "            min = x_c[i]\n",
    "            argmin1 = i\n",
    "    argmin[0]=argmin1\n",
    "    del(x_c[argmin1])\n",
    "    min = math.inf\n",
    "\n",
    "    for i in range(len(x_c)):\n",
    "        if x_c[i] < min:\n",
    "            min = x_c[i]\n",
    "            argmin1 = i\n",
    "    argmin[1]=argmin1\n",
    "    del(x_c[argmin1])\n",
    "    min = math.inf\n",
    "\n",
    "    for i in range(len(x_c)):\n",
    "        if x_c[i] < min:\n",
    "            min = x_c[i]\n",
    "            argmin1 = i\n",
    "    argmin[2]=argmin1\n",
    "    return argmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here for getting error rate for 3 nearest neighbours firstly i am finding the indexes for the 3 nearest points lets say for 0,1 & 2 using the min function we set it as to the infinity.\n",
    "using the for loop we are trying to get the minimum value for that first data point (means in the first for loop its for data point 'zero'). after getting the least value we deleting it from the loop and only selecting the value which has the most number of occurances.\n",
    "Again repeating the same process for the remaining data points as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_3 = np.empty(len(X_test))\n",
    "for i in range(len(X_test)):\n",
    "    pred_index=argmin_finder_3(distance[i])\n",
    "    s=set(y_train)\n",
    "    dict1={}\n",
    "    for v in s:\n",
    "        dict1[v]=0\n",
    "    for j in pred_index:\n",
    "        dict1[y_train[j]]+=1\n",
    "    l=[0]\n",
    "    for k1,v1 in dict1.items():\n",
    "        l.append(v1)\n",
    "    l.sort()\n",
    "    \n",
    "    if(l[-1]==1):\n",
    "        y_pred_3[i] = y_train[pred_index[0]]\n",
    "        break\n",
    "    for k2,v2 in dict1.items():\n",
    "        if(v2==l[-1]):\n",
    "            y_pred_3[i] = k2\n",
    "            \n",
    "            break\n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this y_pred_3 creating the empty set for storing the index values for each of the test data(labels).\n",
    "creating the dictonary so that we can give each label a key because i will be using the same logic for the ionospehere dstaset as well.\n",
    "At the end we are incrementing the value by one unit with its key values so that we can get the label which has the most number of occurances and then at the end we just selecting a label which ahs the most number of occurances. with the help of append we are storing the highest getting occurances.\n",
    "\n",
    "Got the same accuracy and error rate as gor for 1 nearest neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02631578947368421"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_count = sum(y_pred_3!=y_test)\n",
    "error_rate = (error_count/len(X_test))\n",
    "error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the dataset IONOSPEHRE\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "ionosphere_data = np.genfromtxt('ionosphere.txt', delimiter=',', usecols=np.arange(34))\n",
    "ionosphere_target = np.genfromtxt('ionosphere.txt', delimiter=',', usecols=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(ionosphere_data, ionosphere_target, random_state=186)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloaded and uploaded Ionosphere dataset here and splitted it using the train_test_split function and selected the random state as my birthdate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(263, 34) (88, 34) (88,) (263,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def euc_distance(x,y) :\n",
    "    euc_calc = np.empty(len(x))\n",
    "    for i in range(len(x)) :\n",
    "        euc_calc[i] =(x[i] - y[i]) ** 2\n",
    "    answer = np.sum(euc_calc) ** 0.5\n",
    "    return(answer)\n",
    "\n",
    "import math\n",
    "def min_finder(x):\n",
    "    \n",
    "    min = math.inf\n",
    "    for i in range (len(X)):\n",
    "        if X[i] < min:\n",
    "            min = X[i]\n",
    "    return min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmin_finder(X):\n",
    "    min = math.inf\n",
    "    argmin = 0\n",
    "    for i in range (len(X)):\n",
    "        if X[i] < min:\n",
    "            min = X[i]\n",
    "            argmin = i\n",
    "    return argmin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = np.empty(len(X_test)*len(X_train)).reshape(len(X_test),len(X_train))\n",
    "for i in range(len(X_test)):\n",
    "    for j in range(len(X_train)):\n",
    "        distance[i,j] = euc_distance(X_test[i],X_train[j])\n",
    "        \n",
    "        \n",
    "\n",
    "y_pred = np.empty(len(X_test))\n",
    "for i in range(len(X_test)):\n",
    "    y_pred[i] = y_train[argmin_finder(distance[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11363636363636363"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_count = sum(y_pred!=y_test)\n",
    "error_rate = (error_count/len(X_test))\n",
    "error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading and splitting the dataset successfully first calcluated the euclidean distance after that using the min_finder function calculated the minimum value from the whole array.\n",
    "\n",
    "After using the min_finder function, used the argmin_finder for getting the index value of that particular minimum value. lastly created the one empty set to get the distance between test and train sample and stored that into the y_pred to get the final error rate for the 1 nearest neighbour.\n",
    "\n",
    "I have got the error rate as 0.113 and accuracy as 0.89 that is 89%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3NN for the Ionospehre\n",
    "\n",
    "def argmin_finder_3(x):\n",
    "    \n",
    "    min = math.inf\n",
    "    x_c=[i for i in x]\n",
    "    argmin = [0,1,2]\n",
    "    for i in range(len(x_c)):\n",
    "        if x_c[i] < min:\n",
    "            min = x_c[i]\n",
    "            argmin1 = i\n",
    "    argmin[0]=argmin1\n",
    "    del(x_c[argmin1])\n",
    "    min = math.inf\n",
    "\n",
    "    for i in range(len(x_c)):\n",
    "        if x_c[i] < min:\n",
    "            min = x_c[i]\n",
    "            argmin1 = i\n",
    "    argmin[1]=argmin1\n",
    "    del(x_c[argmin1])\n",
    "    min = math.inf\n",
    "\n",
    "    for i in range(len(x_c)):\n",
    "        if x_c[i] < min:\n",
    "            min = x_c[i]\n",
    "            argmin1 = i\n",
    "    argmin[2]=argmin1\n",
    "    return argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_3 = np.empty(len(X_test))\n",
    "for i in range(len(X_test)):\n",
    "    pred_index=argmin_finder_3(distances[i])\n",
    "    s=set(y_train)\n",
    "    dict1={}\n",
    "    for v in s:\n",
    "        dict1[v]=0\n",
    "    for j in pred_index:\n",
    "        dict1[y_train[j]]+=1\n",
    "    l=[0]\n",
    "    for k1,v1 in dict1.items():\n",
    "        l.append(v1)\n",
    "    l.sort()\n",
    "    \n",
    "    if(l[-1]==1):\n",
    "        y_pred_3[i] = y_train[pred_index[0]]\n",
    "        break\n",
    "    for k2,v2 in dict1.items():\n",
    "        if(v2==l[-1]):\n",
    "            y_pred_3[i] = k2\n",
    "            \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19318181818181818"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_count = sum(y_pred_3!=y_test)\n",
    "error_rate = (error_count/len(X_test))\n",
    "error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this y_pred_3 creating the empty set for storing the index values for each of the test data(labels).\n",
    "creating the dictonary so that we can give each label a key because i will be using the same logic for the ionospehere dstaset as well.\n",
    "At the end we are incrementing the value by one unit with its key values so that we can get the label which has the most number of occurances and then at the end we just selecting a label which ahs the most number of occurances. with the help of append we are storing the highest getting occurances.\n",
    "\n",
    "Got the different error rate accuracy for the 3nn for the ionospehere dataset.\n",
    "Error rate=0.19 and accuracy=81%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
